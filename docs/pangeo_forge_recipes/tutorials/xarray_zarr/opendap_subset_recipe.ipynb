{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9de6a449",
   "metadata": {},
   "source": [
    "# NARR: Subsetting and OPeNDAP\n",
    "\n",
    "## About the Dataset\n",
    "\n",
    "This tutorial uses data from NOAA's [North American Regional Reanalysis](https://www.ncei.noaa.gov/products/weather-climate-models/north-american-regional) (NARR)\n",
    "\n",
    "> The North American Regional Reanalysis (NARR) is a model produced by the National Centers for Environmental Prediction (NCEP) that generates reanalyzed data for temperature, wind, moisture, soil, and dozens of other parameters. The NARR model assimilates a large amount of observational data from a variety of sources to produce a long-term picture of weather over North America.\n",
    "\n",
    "For this recipe, we will access the data via [OPeNDAP](https://earthdata.nasa.gov/collaborate/open-data-services-and-software/api/opendap), a widely-used API for remote access of environmental data over HTTP.\n",
    "A key point is that, since we use using OPeNDAP, _there are no input files to download / cache_. We open the data directly from the remote server.\n",
    "\n",
    "The data we will use are catalogged here (3D data on pressure levels): <https://psl.noaa.gov/thredds/catalog/Datasets/NARR/pressure/catalog.html>\n",
    "\n",
    "Let's peek at one file. Xarray should automatically do the right thing with the OPeNDAP url. But just to be safe, we can pass the option, `engine='netcdf4'`, which is needed to open OPeNDAP links correctly. (We will need this again later when writing our recipe.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b4633d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "url = \"https://psl.noaa.gov/thredds/dodsC/Datasets/NARR/pressure/air.197901.nc\"\n",
    "ds = xr.open_dataset(url, engine='netcdf4', decode_cf=\"all\")\n",
    "ds"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ce43c11e",
   "metadata": {},
   "source": [
    "This is just one file.\n",
    "But it's a very big file (several GB)!\n",
    "We will want to break it up by specifying `target_chunks` when we write to Zarr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bdc5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.air._ChunkSizes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "df877352",
   "metadata": {},
   "source": [
    "This tells us that we can subset in the `time` or `level` dimensions, but problably should avoid subsetting in the `x` and `y` dimensions.\n",
    "\n",
    "Also note the presence of the `Lambert_Conformal` data variable. This should be a coordinate. So we will need to write a custom transform to make that change.\n",
    "\n",
    "## Define File Pattern\n",
    "\n",
    "We are now ready to define the `FilePattern` for the recipe. There is one file per month. So we start with a function like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23de17b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_function(time):\n",
    "    return f\"https://psl.noaa.gov/thredds/dodsC/Datasets/NARR/pressure/air.{time}.nc\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7dd39e3",
   "metadata": {},
   "source": [
    "To keep things short and simple for this tutorial, we will just use one file, and subset it into many chunks.\n",
    "But we could easily add more months to build up the entire dataset.\n",
    "Since each file is monthly, and the number of days per months varies, we cannot set `nitems_per_input` in the `ConcatDim`.\n",
    "\n",
    "```{note}\n",
    "It's important that we specify `file_type=\"opendap\"` when creating a FilePattern with OPeNDAP URLs.\n",
    "OPeNDAP is actually an API, so there are no files to download. \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcaf511",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pangeo_forge_recipes.patterns import FilePattern, ConcatDim, MergeDim\n",
    "time_dim = ConcatDim(\"time\", [\"197901\"])\n",
    "pattern = FilePattern(format_function, time_dim, file_type=\"opendap\")\n",
    "pattern"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "977bcb43",
   "metadata": {},
   "source": [
    "## Define the Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c33246c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam as beam\n",
    "from pangeo_forge_recipes.transforms import OpenURLWithFSSpec, OpenWithXarray, StoreToZarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e6808c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pangeo_forge_recipes.transforms import Indexed, T\n",
    "\n",
    "class SetProjectionAsCoord(beam.PTransform):\n",
    "    \"\"\"A preprocessing function which will assign the `Lambert_Conformal` variable as a coordinate variable.\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def _set_projection_as_coord(item: Indexed[T]) -> Indexed[T]:\n",
    "        index, ds = item\n",
    "        ds = ds.set_coords([\"Lambert_Conformal\"])\n",
    "        return index, ds\n",
    "\n",
    "    def expand(self, pcoll: beam.PCollection) -> beam.PCollection:\n",
    "        return pcoll | beam.Map(self._set_projection_as_coord)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "69e978e1",
   "metadata": {},
   "source": [
    "We now define a target location for our recipe. Here we just use a temporary directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898329cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tempfile import TemporaryDirectory\n",
    "td = TemporaryDirectory()\n",
    "target_root = td.name\n",
    "store_name = \"output.zarr\"\n",
    "target_store = os.path.join(target_root, store_name)\n",
    "target_store"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b04aaaa5",
   "metadata": {},
   "source": [
    "Now we put together the necessary PTransforms. In this pipeline we're adding in the argument, `target_chunks`, which is a dictionary describing how we want the output dataset to be chunked. In this example, we are specifying single time chunks (`{\"time\": 1}`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f2acde",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = (\n",
    "    beam.Create(pattern.items())\n",
    "    | OpenWithXarray(file_type=pattern.file_type)\n",
    "    | SetProjectionAsCoord()\n",
    "    | StoreToZarr(\n",
    "        store_name=store_name,\n",
    "        target_root=target_root,\n",
    "        combine_dims=pattern.combine_dim_keys,\n",
    "        target_chunks={\"time\": 1}\n",
    "    )\n",
    ")\n",
    "transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16262be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with beam.Pipeline() as p:\n",
    "    p | transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7abe582",
   "metadata": {},
   "source": [
    "## Check The Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce52842",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_target =  xr.open_dataset(target_store, engine=\"zarr\", chunks={})\n",
    "ds_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce7f2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_target.air.isel(level=0).mean(\"time\").plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6f405c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
